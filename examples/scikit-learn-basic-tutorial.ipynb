{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "## Ref: https://happycoder.org/2017/10/14/python-data-science-and-machine-learning-scikit-learn-basic-tutorial/\n",
    "# 1.明確定義問題 (Problem Definition)\n",
    "# 2.獲取資料與探索性資料分析 (Get Data & Exploratory Data Analysis)\n",
    "# 3.資料預處理與特徵工程 (Data Clean/Preprocessing & Feature Engineering)\n",
    "# 4.訓練模型與校調 (Model Training)\n",
    "# 5.模型驗證 (Model Predict & Testing)\n",
    "# 6.模型優化 (Model Optimization)\n",
    "# 7.上線運行 (Deploy Model)\n",
    "\n",
    "# 引入 numpy、pd 和 sklearn(scikit-learn) 模組\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "# 引入 train_test_split 分割方法，注意在 sklearn v0.18 後 train_test_split 從 sklearn.cross_validation 子模組搬到 sklearn.model_selection 中\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 引入 KNeighbors 模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DESCR', 'data', 'target_names', 'feature_names', 'target'])\n",
      "### data ###\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "### target ###\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "### target_names ###\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "### feature_names ###\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 2.獲取資料與探索性資料分析 (Get Data & Exploratory Data Analysis)\n",
    "\n",
    "# 引入 iris 資料集\n",
    "raw_iris = datasets.load_iris()\n",
    "# 探索性分析 Exploratory data analysis，了解資料集內容\n",
    "# 先印出 key 值，列出有哪些值：['data', 'target', 'target_names', 'DESCR', 'feature_names']\n",
    "print(raw_iris.keys())\n",
    "\n",
    "# 印出 feature 值\n",
    "print('### data ###')\n",
    "print(raw_iris['data'])\n",
    "\n",
    "# 印出目標值，分別對應的是三種花的類別：['setosa 山鳶尾' 'versicolor 變色鳶尾' 'virginica 維吉尼亞鳶尾']\n",
    "print('### target ###')\n",
    "print(raw_iris['target'])\n",
    "\n",
    "# 印出目標標籤，三種花的類別：['setosa' 'versicolor' 'virginica']\n",
    "print('### target_names ###')\n",
    "print(raw_iris['target_names'])\n",
    "\n",
    "# 印出資料集內容描述\n",
    "#print(raw_iris['DESCR'])\n",
    "\n",
    "# 印出屬性名稱，['sepal length 花萼長度 (cm)', 'sepal width 花萼寬度 (cm)', 'petal length 花蕊長度 (cm)', 'petal width 花蕊寬度 (cm)']\n",
    "print('### feature_names ###')\n",
    "print(raw_iris['feature_names'])\n",
    "\n",
    "# 類別種類\n",
    "print(np.unique(raw_iris.target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### train_test_split ###\n",
      "150\n",
      "     0\n",
      "118  2\n",
      "88   1\n",
      "105  2\n",
      "47   0\n",
      "106  2\n",
      "45   0\n",
      "98   1\n",
      "127  2\n",
      "50   1\n",
      "90   1\n",
      "97   1\n",
      "142  2\n",
      "77   1\n",
      "149  2\n",
      "84   1\n",
      "25   0\n",
      "119  2\n",
      "15   0\n",
      "87   1\n",
      "75   1\n",
      "36   0\n",
      "138  2\n",
      "16   0\n",
      "111  2\n",
      "60   1\n",
      "144  2\n",
      "44   0\n",
      "42   0\n",
      "145  2\n",
      "9    0\n",
      "..  ..\n",
      "26   0\n",
      "2    0\n",
      "20   0\n",
      "80   1\n",
      "0    0\n",
      "49   0\n",
      "101  2\n",
      "103  2\n",
      "38   0\n",
      "99   1\n",
      "132  2\n",
      "96   1\n",
      "79   1\n",
      "140  2\n",
      "74   1\n",
      "117  2\n",
      "71   1\n",
      "134  2\n",
      "41   0\n",
      "32   0\n",
      "58   1\n",
      "120  2\n",
      "86   1\n",
      "69   1\n",
      "130  2\n",
      "35   0\n",
      "27   0\n",
      "17   0\n",
      "46   0\n",
      "93   1\n",
      "\n",
      "[105 rows x 1 columns]\n",
      "105\n",
      "     0\n",
      "5    0\n",
      "33   0\n",
      "52   1\n",
      "53   1\n",
      "13   0\n",
      "91   1\n",
      "54   1\n",
      "102  2\n",
      "78   1\n",
      "95   1\n",
      "12   0\n",
      "135  2\n",
      "92   1\n",
      "104  2\n",
      "66   1\n",
      "110  2\n",
      "146  2\n",
      "115  2\n",
      "129  2\n",
      "19   0\n",
      "21   0\n",
      "100  2\n",
      "107  2\n",
      "82   1\n",
      "37   0\n",
      "147  2\n",
      "10   0\n",
      "123  2\n",
      "108  2\n",
      "70   1\n",
      "18   0\n",
      "85   1\n",
      "29   0\n",
      "126  2\n",
      "28   0\n",
      "137  2\n",
      "125  2\n",
      "116  2\n",
      "89   1\n",
      "64   1\n",
      "133  2\n",
      "59   1\n",
      "131  2\n",
      "143  2\n",
      "6    0\n",
      "45\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## 3.資料預處理與特徵工程 (Data Clean/Preprocessing & Feature Engineering)\n",
    "\n",
    "# 將資料轉為 pandas DataFrame\n",
    "# data 為觀察目標變數\n",
    "df_X = pd.DataFrame(raw_iris.data)\n",
    "# target 為預測變數\n",
    "df_y = pd.DataFrame(raw_iris.target)\n",
    "# 將資料切分為 training data 和 testing data，其中 random_state 若設為 0 或不設則即便實例不同但因種子相同產生同樣隨機編號，若設為 1 則每次隨機產生不同編號\n",
    "# test_size 為切分 training data 和 testing data 的比例\n",
    "print('### train_test_split ###')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3)\n",
    "\n",
    "# 印出所有資料集筆數\n",
    "print(len(df_y))\n",
    "\n",
    "# 印出切分 y_train 的數量為所有資料集的 70%，共 105 筆\n",
    "print(y_train)\n",
    "print(len(y_train))\n",
    "\n",
    "# 印出切分的 y_test 資料為所有資料集的 30%，共 45 筆\n",
    "print(y_test)\n",
    "print(len(y_test))\n",
    "\n",
    "\n",
    "# 初始化 LinearSVC 實例\n",
    "lin_clf = LinearSVC()\n",
    "# 使用 fit 來建置模型，其參數接收 training data matrix, testing data array，所以進行 y_train.values.ravel() Data Frame 轉換\n",
    "lin_clf.fit(X_train, y_train.values.ravel())\n",
    "print(lin_clf)\n",
    "\n",
    "# 初始化 KNeighborsClassifier 實例\n",
    "knn = KNeighborsClassifier()\n",
    "# 使用 fit 來建置模型，其參數接收 training data matrix, testing data array，所以進行 y_train.values.ravel() 轉換\n",
    "knn.fit(X_train, y_train.values.ravel())\n",
    "print(knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 1 1 2 1 1 0 2 1 2 2 2 2 2 1 0 0 2 2 1 0 2 0 2 2 2 0 2 0 2 0 2 2\n",
      " 2 1 1 1 1 2 2 0]\n",
      "0.8888888888888888\n",
      "[0 0 1 1 0 1 1 2 1 1 0 2 1 2 1 2 2 2 2 0 0 2 2 1 0 2 0 2 2 2 0 1 0 1 0 2 2\n",
      " 2 1 1 1 1 2 2 0]\n",
      "[[1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.2 0.8]\n",
      " [0.  0.4 0.6]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.2 0.8]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.4 0.6]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.4 0.6]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.8 0.2]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.6 0.4]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.6 0.4]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]]\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## 4.模型驗證 (Model Predict & Testing)\n",
    "\n",
    "# 使用 X_test 來預測結果\n",
    "print(lin_clf.predict(X_test))\n",
    "# 印出預測準確率\n",
    "print(lin_clf.score(X_test, y_test))\n",
    "\n",
    "# 使用 X_test 來預測結果\n",
    "print(knn.predict(X_test))\n",
    "# 印出 testing data 預測標籤機率\n",
    "print(knn.predict_proba(X_test))\n",
    "# 印出預測準確率\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
